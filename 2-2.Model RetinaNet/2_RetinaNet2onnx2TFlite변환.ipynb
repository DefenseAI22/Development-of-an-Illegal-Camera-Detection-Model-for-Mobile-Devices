{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## onnx -> TFLITE 코드 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on2tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is valid!\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "model = onnx.load(\"Last_P2_Lens.onnx\")\n",
    "# /Users/parkjunhui/Desktop/Spresto/480_retinanet_Lens.onnx\n",
    "onnx.checker.check_model(model)\n",
    "print(\"Model is valid!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[07mModel optimizing started\u001b[0m ============================================================\n",
      "Simplifying\u001b[33m...\u001b[0m\n",
      "Finish! Here is the difference:\n",
      "┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOriginal Model\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSimplified Model\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
      "│ Add        │ 3              │ 3                │\n",
      "│ Constant   │ 46             │ 46               │\n",
      "│ Conv       │ 23             │ 23               │\n",
      "│ MaxPool    │ 1              │ 1                │\n",
      "│ Relu       │ 18             │ 18               │\n",
      "│ Model Size │ 21.8MiB        │ 21.8MiB          │\n",
      "└────────────┴────────────────┴──────────────────┘\n",
      "\n",
      "Simplifying\u001b[33m...\u001b[0m\n",
      "Finish! Here is the difference:\n",
      "┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOriginal Model\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSimplified Model\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
      "│ Add        │ 3              │ 3                │\n",
      "│ Constant   │ 46             │ 46               │\n",
      "│ Conv       │ 23             │ 23               │\n",
      "│ MaxPool    │ 1              │ 1                │\n",
      "│ Relu       │ 18             │ 18               │\n",
      "│ Model Size │ 21.8MiB        │ 21.8MiB          │\n",
      "└────────────┴────────────────┴──────────────────┘\n",
      "\n",
      "Simplifying\u001b[33m...\u001b[0m\n",
      "Finish! Here is the difference:\n",
      "┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOriginal Model\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSimplified Model\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
      "│ Add        │ 3              │ 3                │\n",
      "│ Constant   │ 46             │ 46               │\n",
      "│ Conv       │ 23             │ 23               │\n",
      "│ MaxPool    │ 1              │ 1                │\n",
      "│ Relu       │ 18             │ 18               │\n",
      "│ Model Size │ 21.8MiB        │ 21.8MiB          │\n",
      "└────────────┴────────────────┴──────────────────┘\n",
      "\n",
      "\u001b[32mModel optimizing complete!\u001b[0m\n",
      "\n",
      "\u001b[07mAutomatic generation of each OP name started\u001b[0m ========================================\n",
      "\u001b[32mAutomatic generation of each OP name complete!\u001b[0m\n",
      "\n",
      "\u001b[07mModel loaded\u001b[0m ========================================================================\n",
      "\n",
      "\u001b[07mModel conversion started\u001b[0m ============================================================\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32minput_op_name\u001b[0m: input \u001b[32mshape\u001b[0m: [1, 3, 320, 320] \u001b[32mdtype\u001b[0m: float32\n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m2 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/bottom_up/stem/conv1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input \u001b[36mshape\u001b[0m: [1, 3, 320, 320] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_347 \u001b[36mshape\u001b[0m: [64, 3, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_348 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/bottom_up/stem/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 160, 160] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 326, 326, 3) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (7, 7, 3, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add/Add:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m3 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/bottom_up/stem/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/bottom_up/stem/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 160, 160] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/bottom_up/stem/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 160, 160] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add/Add:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu/Relu:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m4 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MaxPool\u001b[35m onnx_op_name\u001b[0m: /backbone/bottom_up/stem/MaxPool\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/bottom_up/stem/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 160, 160] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/bottom_up/stem/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[33mWARNING:\u001b[0m Tensorflow incompatible padding detected. Extra pad layer is inserted automatically. \n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: max_pool_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu/Relu:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.kernel_shape\u001b[0m: \u001b[34mval\u001b[0m: [3, 3] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: [[0, 0], [1, 1], [1, 1], [0, 0]] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.ceil_mode\u001b[0m: \u001b[34mval\u001b[0m: False \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool2d/MaxPool2d:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.2.output1\u001b[0m: \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m5 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/bottom_up/res2/res2.0/conv1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/bottom_up/stem/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_350 \u001b[36mshape\u001b[0m: [64, 64, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_351 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/bottom_up/res2/res2.0/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool2d/MaxPool2d:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_1/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m6 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/bottom_up/res2/res2.0/shortcut/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/bottom_up/stem/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_359 \u001b[36mshape\u001b[0m: [256, 64, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_360 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/bottom_up/res2/res2.0/shortcut/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool2d/MaxPool2d:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 64, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_2/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m7 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/bottom_up/res2/res2.0/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/bottom_up/res2/res2.0/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/bottom_up/res2/res2.0/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_1/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_1/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m8 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/bottom_up/res2/res2.0/conv2/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/bottom_up/res2/res2.0/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_353 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_354 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/bottom_up/res2/res2.0/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_1/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_3/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m9 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/bottom_up/res2/res2.0/Relu_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/bottom_up/res2/res2.0/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/bottom_up/res2/res2.0/Relu_1_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_3/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_2/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m10 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/bottom_up/res2/res2.0/conv3/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/bottom_up/res2/res2.0/Relu_1_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_356 \u001b[36mshape\u001b[0m: [256, 64, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_357 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/bottom_up/res2/res2.0/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_2/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 64, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_4/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m11 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /backbone/bottom_up/res2/res2.0/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/bottom_up/res2/res2.0/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/bottom_up/res2/res2.0/shortcut/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/bottom_up/res2/res2.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_4/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_2/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_6/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m12 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/bottom_up/res2/res2.0/Relu_2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/bottom_up/res2/res2.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/bottom_up/res2/res2.0/Relu_2_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_6/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_3/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m13 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/bottom_up/res2/res2.1/conv1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/bottom_up/res2/res2.0/Relu_2_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_362 \u001b[36mshape\u001b[0m: [64, 256, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_363 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/bottom_up/res2/res2.1/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_3/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 256, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_7/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m14 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/bottom_up/res2/res2.1/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/bottom_up/res2/res2.1/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/bottom_up/res2/res2.1/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_7/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_4/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m15 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/bottom_up/res2/res2.1/conv2/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/bottom_up/res2/res2.1/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_365 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_366 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/bottom_up/res2/res2.1/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_4/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_8/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m16 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/bottom_up/res2/res2.1/Relu_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/bottom_up/res2/res2.1/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/bottom_up/res2/res2.1/Relu_1_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_8/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_5/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m17 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/bottom_up/res2/res2.1/conv3/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/bottom_up/res2/res2.1/Relu_1_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_368 \u001b[36mshape\u001b[0m: [256, 64, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_369 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/bottom_up/res2/res2.1/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_5/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 64, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_9/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m18 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /backbone/bottom_up/res2/res2.1/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/bottom_up/res2/res2.1/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/bottom_up/res2/res2.0/Relu_2_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/bottom_up/res2/res2.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_9/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_3/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_11/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m19 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/bottom_up/res2/res2.1/Relu_2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/bottom_up/res2/res2.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/bottom_up/res2/res2.1/Relu_2_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_11/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_6/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m20 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/bottom_up/res2/res2.2/conv1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/bottom_up/res2/res2.1/Relu_2_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_371 \u001b[36mshape\u001b[0m: [64, 256, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_372 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/bottom_up/res2/res2.2/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_6/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 256, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_12/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m21 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/bottom_up/res2/res2.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/bottom_up/res2/res2.2/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/bottom_up/res2/res2.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_12/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_7/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m22 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/bottom_up/res2/res2.2/conv2/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/bottom_up/res2/res2.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_374 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_375 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/bottom_up/res2/res2.2/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_7/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_13/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m23 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/bottom_up/res2/res2.2/Relu_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/bottom_up/res2/res2.2/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/bottom_up/res2/res2.2/Relu_1_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_13/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_8/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m24 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/bottom_up/res2/res2.2/conv3/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/bottom_up/res2/res2.2/Relu_1_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_377 \u001b[36mshape\u001b[0m: [256, 64, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_378 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/bottom_up/res2/res2.2/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_8/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 64, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_14/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m25 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /backbone/bottom_up/res2/res2.2/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/bottom_up/res2/res2.2/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/bottom_up/res2/res2.1/Relu_2_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/bottom_up/res2/res2.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_14/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_6/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_16/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m26 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/bottom_up/res2/res2.2/Relu_2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/bottom_up/res2/res2.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/bottom_up/res2/res2.2/Relu_2_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_16/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_9/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m27 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/fpn_lateral2/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/bottom_up/res2/res2.2/Relu_2_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: d2_model.backbone.fpn_lateral2.weight \u001b[36mshape\u001b[0m: [256, 256, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: d2_model.backbone.fpn_lateral2.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/fpn_lateral2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_9/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_17/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m28 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/fpn_output2/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/fpn_lateral2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: d2_model.backbone.fpn_output2.weight \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: d2_model.backbone.fpn_output2.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/fpn_output2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_17/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_18/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m29 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /head/cls_subnet/cls_subnet.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/fpn_output2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: d2_model.head.cls_subnet.0.weight \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: d2_model.head.cls_subnet.0.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /head/cls_subnet/cls_subnet.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_18/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_19/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m30 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /head/bbox_subnet/bbox_subnet.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/fpn_output2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: d2_model.head.bbox_subnet.0.weight \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: d2_model.head.bbox_subnet.0.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /head/bbox_subnet/bbox_subnet.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_18/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_20/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m31 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /head/cls_subnet/cls_subnet.1/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /head/cls_subnet/cls_subnet.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /head/cls_subnet/cls_subnet.1/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_19/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_10/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m32 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /head/bbox_subnet/bbox_subnet.1/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /head/bbox_subnet/bbox_subnet.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /head/bbox_subnet/bbox_subnet.1/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_20/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_11/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m33 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /head/cls_subnet/cls_subnet.2/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /head/cls_subnet/cls_subnet.1/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: d2_model.head.cls_subnet.2.weight \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: d2_model.head.cls_subnet.2.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /head/cls_subnet/cls_subnet.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_10/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_21/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m34 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /head/bbox_subnet/bbox_subnet.2/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /head/bbox_subnet/bbox_subnet.1/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: d2_model.head.bbox_subnet.2.weight \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: d2_model.head.bbox_subnet.2.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /head/bbox_subnet/bbox_subnet.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_11/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_22/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m35 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /head/cls_subnet/cls_subnet.3/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /head/cls_subnet/cls_subnet.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /head/cls_subnet/cls_subnet.3/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_21/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_12/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m36 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /head/bbox_subnet/bbox_subnet.3/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /head/bbox_subnet/bbox_subnet.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /head/bbox_subnet/bbox_subnet.3/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_22/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_13/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m37 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /head/cls_subnet/cls_subnet.4/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /head/cls_subnet/cls_subnet.3/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: d2_model.head.cls_subnet.4.weight \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: d2_model.head.cls_subnet.4.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /head/cls_subnet/cls_subnet.4/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_12/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_23/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m38 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /head/bbox_subnet/bbox_subnet.4/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /head/bbox_subnet/bbox_subnet.3/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: d2_model.head.bbox_subnet.4.weight \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: d2_model.head.bbox_subnet.4.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /head/bbox_subnet/bbox_subnet.4/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_13/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_24/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m39 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /head/cls_subnet/cls_subnet.5/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /head/cls_subnet/cls_subnet.4/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /head/cls_subnet/cls_subnet.5/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_23/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_14/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m40 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /head/bbox_subnet/bbox_subnet.5/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /head/bbox_subnet/bbox_subnet.4/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /head/bbox_subnet/bbox_subnet.5/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_24/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_15/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m41 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /head/cls_subnet/cls_subnet.6/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /head/cls_subnet/cls_subnet.5/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: d2_model.head.cls_subnet.6.weight \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: d2_model.head.cls_subnet.6.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /head/cls_subnet/cls_subnet.6/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_14/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_25/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m42 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /head/bbox_subnet/bbox_subnet.6/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /head/bbox_subnet/bbox_subnet.5/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: d2_model.head.bbox_subnet.6.weight \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: d2_model.head.bbox_subnet.6.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /head/bbox_subnet/bbox_subnet.6/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_15/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_26/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m43 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /head/cls_subnet/cls_subnet.7/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /head/cls_subnet/cls_subnet.6/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /head/cls_subnet/cls_subnet.7/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_25/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_16/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m44 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /head/bbox_subnet/bbox_subnet.7/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /head/bbox_subnet/bbox_subnet.6/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /head/bbox_subnet/bbox_subnet.7/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_26/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_17/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m45 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /head/cls_score/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /head/cls_subnet/cls_subnet.7/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: d2_model.head.cls_score.weight \u001b[36mshape\u001b[0m: [9, 256, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: d2_model.head.cls_score.bias \u001b[36mshape\u001b[0m: [9] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: p2_cls_logits \u001b[36mshape\u001b[0m: [1, 9, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_16/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 9) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (9,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_27/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 9) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m46 / 46\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /head/bbox_pred/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /head/bbox_subnet/bbox_subnet.7/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: d2_model.head.bbox_pred.weight \u001b[36mshape\u001b[0m: [36, 256, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: d2_model.head.bbox_pred.bias \u001b[36mshape\u001b[0m: [36] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: p2_bbox_reg \u001b[36mshape\u001b[0m: [1, 36, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_17/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 36) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (36,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_28/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 36) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[07msaved_model output started\u001b[0m ==========================================================\n",
      "\u001b[32msaved_model output complete!\u001b[0m\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1737550612.580739 21976866 devices.cc:76] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1737550612.581448 21976866 single_machine.cc:361] Starting new session\n",
      "W0000 00:00:1737550612.735543 21976866 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1737550612.735559 21976866 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "\u001b[32mFloat32 tflite output complete!\u001b[0m\n",
      "I0000 00:00:1737550622.484883 21976866 devices.cc:76] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "I0000 00:00:1737550622.484953 21976866 single_machine.cc:361] Starting new session\n",
      "W0000 00:00:1737550622.603338 21976866 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1737550622.603354 21976866 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "\u001b[32mFloat16 tflite output complete!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 이제 시스템 명령어 실행\n",
    "!onnx2tf \\\n",
    "  -i Last_P2_Lens.onnx\\\n",
    "  -o Last_P2_Lens_tf \\\n",
    "  --copy_onnx_input_output_names_to_tflite\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-lite로 모델 사용후 시각화까지 한번 해보기 코드\n",
    "* 위에 모델 바꿀때마다 바꿔줄꺼 바꿔보면서\n",
    " 디버깅해봐야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Original image shape: (1920, 1080, 3)\n",
      "[DEBUG] Before subtract mean => pixel sample: [36. 48. 58.]\n",
      "[DEBUG] After subtract mean => pixel sample: [-67.53  -68.28  -65.675]\n",
      "[DEBUG] input_data shape: (1, 320, 320, 3)\n",
      "=== [DEBUG] TFLite raw outputs ===\n",
      "P3 cls: (1, 80, 80, 9), bbox: (1, 80, 80, 36)\n",
      "P4 cls: (1, 40, 40, 9), bbox: (1, 40, 40, 36)\n",
      "P5 cls: (1, 20, 20, 9), bbox: (1, 20, 20, 36)\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "# 1) TFLite 모델 로드\n",
    "############################\n",
    "model_path = \"/Users/parkjunhui/Desktop/Spresto/320_retinanet_Lens_tf/320_retinanet_Lens_float32.tflite\"\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "############################\n",
    "# 2) 이미지 로드 & 전처리\n",
    "############################\n",
    "image_path = \"/Users/parkjunhui/Desktop/Spresto/test.jpg\"\n",
    "image_bgr = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "if image_bgr is None:\n",
    "    raise FileNotFoundError(f\"이미지 로드 실패: {image_path}\")\n",
    "\n",
    "print(\"[DEBUG] Original image shape:\", image_bgr.shape)\n",
    "\n",
    "# Resize 640x640\n",
    "resized_bgr = cv2.resize(image_bgr, (320,320))\n",
    "# BGR -> RGB\n",
    "# resized_rgb = cv2.cvtColor(resized_bgr, cv2.COLOR_BGR2RGB)\n",
    "float_bgr = resized_bgr.astype(np.float32)\n",
    "# Mean 빼기\n",
    "print(\"[DEBUG] Before subtract mean => pixel sample:\", float_bgr[0,0])  # 첫 픽셀 (B,G,R) 값\n",
    "float_bgr[...,0] -= 103.53  # B\n",
    "float_bgr[...,1] -= 116.28  # G\n",
    "float_bgr[...,2] -= 123.675 # R\n",
    "print(\"[DEBUG] After subtract mean => pixel sample:\", float_bgr[0,0])\n",
    "input_data = np.expand_dims(float_bgr, axis=0)\n",
    "print(\"[DEBUG] input_data shape:\", input_data.shape)\n",
    "\n",
    "\n",
    "# TFLite 입력 세팅 & 추론\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "interpreter.invoke()\n",
    "\n",
    "############################\n",
    "# 3) TFLite 출력 얻기\n",
    "############################\n",
    "# RetinaNet: p3~p7, 총 10개 노드\n",
    "# cls_logits: p3_cls_logits / p4_cls_logits / p5_cls_logits / p6_cls_logits / p7_cls_logits\n",
    "# bbox_reg  : p3_bbox_reg  / p4_bbox_reg  / p5_bbox_reg  / p6_bbox_reg  / p7_bbox_reg\n",
    "\n",
    "# 순서상 output_details[0]~[4]: cls_logits, [5]~[9]: bbox_reg\n",
    "cls_logits_list = []\n",
    "bbox_reg_list   = []\n",
    "for i in range(3):\n",
    "    cls_logits_list.append(interpreter.get_tensor(output_details[i]['index']))\n",
    "    bbox_reg_list.append(interpreter.get_tensor(output_details[i+3]['index']))\n",
    "\n",
    "\n",
    "print(\"=== [DEBUG] TFLite raw outputs ===\")\n",
    "for i, (cl, br) in enumerate(zip(cls_logits_list, bbox_reg_list)):\n",
    "    print(f\"P{i+3} cls: {cl.shape}, bbox: {br.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# 4) 앵커 생성 함수 (예시)\n",
    "############################\n",
    "def generate_anchors_one_level(\n",
    "    grid_height, grid_width, stride,\n",
    "    base_size,\n",
    "    aspect_ratios=[0.5, 1.0, 2.0],\n",
    "    offset=0.0\n",
    "):\n",
    "    \"\"\"\n",
    "    scale 3개 사용: base_size*(2^(0/3)), base_size*(2^(1/3)), base_size*(2^(2/3))\n",
    "    \"\"\"\n",
    "    # make 3 scales\n",
    "    sizes = [base_size*(2**(i/3)) for i in range(3)]\n",
    "\n",
    "    # 1) canonical anchors (9,4) around center (0,0)\n",
    "    base_anchors = []\n",
    "    for size in sizes:\n",
    "        area = size*size\n",
    "        for ar in aspect_ratios:\n",
    "            w = math.sqrt(area/ar)\n",
    "            h = ar * w\n",
    "            x1, y1 = -w/2.0, -h/2.0\n",
    "            x2, y2 = +w/2.0, +h/2.0\n",
    "            base_anchors.append([x1,y1,x2,y2])\n",
    "    base_anchors = np.array(base_anchors, dtype=np.float32)  # (9,4)\n",
    "\n",
    "    # 2) shift grid\n",
    "    shifts_x = (np.arange(grid_width) + offset)*stride\n",
    "    shifts_y = (np.arange(grid_height) + offset)*stride\n",
    "    shift_y, shift_x = np.meshgrid(shifts_y, shifts_x, indexing='ij')\n",
    "\n",
    "    shift_x = shift_x.reshape(-1)\n",
    "    shift_y = shift_y.reshape(-1)\n",
    "\n",
    "    # shape=(HW,1,4)\n",
    "    shifts = np.stack([shift_x, shift_y, shift_x, shift_y], axis=1)\n",
    "    # broadcast sum\n",
    "    K = shifts.shape[0]\n",
    "    A = base_anchors.shape[0]\n",
    "    all_anchors = (\n",
    "        shifts.reshape(K,1,4) + base_anchors.reshape(1,A,4)\n",
    "    ).reshape(K*A, 4)\n",
    "    return all_anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_anchors_p2to4(feature_shapes):\n",
    "    \"\"\"\n",
    "    예: p3~p7에 대해,\n",
    "    strides = [8,16,32,64,128]\n",
    "    base_sizes = [32,64,128,256,512]\n",
    "    feature_shapes: 예) [(80,80),(40,40),(20,20),(10,10),(5,5)]\n",
    "    \"\"\"\n",
    "    strides = [4,8,16]\n",
    "    base_sizes = [16,32,64]\n",
    "    anchors_all = []\n",
    "    for i, (H,W) in enumerate(feature_shapes):\n",
    "        anchors_l = generate_anchors_one_level(\n",
    "            grid_height=H, grid_width=W,\n",
    "            stride=strides[i],\n",
    "            base_size=base_sizes[i],\n",
    "        )\n",
    "        anchors_all.append(anchors_l)\n",
    "    return anchors_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# 5) 디코딩 함수\n",
    "############################\n",
    "def decode_boxes(deltas, anchors):\n",
    "    \"\"\"\n",
    "    deltas: shape=(N,4) -> (dx,dy,dw,dh)\n",
    "    anchors: shape=(N,4) -> (x1,y1,x2,y2)\n",
    "    output: shape=(N,4) -> decoded boxes\n",
    "    \"\"\"\n",
    "    xa = 0.5*(anchors[:,0]+anchors[:,2])  # center x\n",
    "    ya = 0.5*(anchors[:,1]+anchors[:,3])  # center y\n",
    "    wa = anchors[:,2] - anchors[:,0]\n",
    "    ha = anchors[:,3] - anchors[:,1]\n",
    "\n",
    "    dx = deltas[:,0]\n",
    "    dy = deltas[:,1]\n",
    "    dw = deltas[:,2]\n",
    "    dh = deltas[:,3]\n",
    "\n",
    "    cx = xa + dx*wa\n",
    "    cy = ya + dy*ha\n",
    "    w = np.exp(dw)*wa\n",
    "    h = np.exp(dh)*ha\n",
    "\n",
    "    x1 = cx - 0.5*w\n",
    "    y1 = cy - 0.5*h\n",
    "    x2 = cx + 0.5*w\n",
    "    y2 = cy + 0.5*h\n",
    "    return np.stack([x1,y1,x2,y2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_np(box1, boxes):\n",
    "    \"\"\"\n",
    "    box1: shape=(4,),  (x1,y1,x2,y2)\n",
    "    boxes: shape=(N,4)\n",
    "    return: shape=(N,) 각 box와 box1의 IoU\n",
    "    \"\"\"\n",
    "    # (x1,y1,x2,y2)에서 x2<x1인 케이스는 없다고 가정(정상 bbox)\n",
    "    x1 = np.maximum(box1[0], boxes[:,0])\n",
    "    y1 = np.maximum(box1[1], boxes[:,1])\n",
    "    x2 = np.minimum(box1[2], boxes[:,2])\n",
    "    y2 = np.minimum(box1[3], boxes[:,3])\n",
    "    \n",
    "    inter_w = np.maximum(0.0, x2 - x1)\n",
    "    inter_h = np.maximum(0.0, y2 - y1)\n",
    "    inter_area = inter_w * inter_h\n",
    "    \n",
    "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area2 = (boxes[:,2] - boxes[:,0]) * (boxes[:,3] - boxes[:,1])\n",
    "    union = area1 + area2 - inter_area\n",
    "    \n",
    "    eps = 1e-6\n",
    "    iou = inter_area / (union + eps)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms_single_class(boxes, scores, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    boxes: shape=(N,4)\n",
    "    scores: shape=(N,)\n",
    "    각 box의 스코어를 내림차순으로 정렬 후, \n",
    "    IoU가 임계값을 넘는 box를 제거하는 \"Greedy NMS\" 구현.\n",
    "    return: NMS 후 살아남은 박스의 인덱스(ascending이 아닌, 선택 순서).\n",
    "    \"\"\"\n",
    "    # 스코어 내림차순 정렬\n",
    "    order = np.argsort(-scores)  # descending\n",
    "    keep_indices = []\n",
    "\n",
    "    while len(order) > 0:\n",
    "        i = order[0]\n",
    "        keep_indices.append(i)\n",
    "        \n",
    "        if len(order) == 1:\n",
    "            break\n",
    "\n",
    "        # 현재 선택된 box i와의 IoU\n",
    "        ious = iou_np(boxes[i], boxes[order[1:]])\n",
    "        # IoU가 임계값 넘는 인덱스 제거\n",
    "        mask = ious <= iou_threshold\n",
    "        # order[1:][mask]만 남기기\n",
    "        order = order[1:][mask]\n",
    "\n",
    "    return keep_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms_classwise_np(boxes, scores, classes, iou_threshold=0.5, max_detections=100):\n",
    "    \"\"\"\n",
    "    boxes:   shape=(N,4)\n",
    "    scores:  shape=(N,)\n",
    "    classes: shape=(N,)  (int)\n",
    "    1) unique classes를 찾아, 각각에 대해 nms_single_class\n",
    "    2) 최종 인덱스 모아, 스코어 기준으로 재정렬\n",
    "    3) top max_detections\n",
    "    return: 최종 살아남은 인덱스(오름차순 순서는 아님)\n",
    "    \"\"\"\n",
    "    unique_classes = np.unique(classes)\n",
    "    keep_indices_all = []\n",
    "\n",
    "    for c in unique_classes:\n",
    "        # 해당 클래스 c에 속하는 인덱스만 추출\n",
    "        c_inds = np.where(classes == c)[0]\n",
    "        if len(c_inds) == 0:\n",
    "            continue\n",
    "        c_boxes  = boxes[c_inds]\n",
    "        c_scores = scores[c_inds]\n",
    "\n",
    "        # 단일 클래스 NMS\n",
    "        keep_c = nms_single_class(c_boxes, c_scores, iou_threshold)\n",
    "        # 실제 전역 인덱스로 변환\n",
    "        keep_indices_all.extend(c_inds[k] for k in keep_c)\n",
    "\n",
    "    if len(keep_indices_all) == 0:\n",
    "        return np.array([], dtype=np.int64)\n",
    "\n",
    "    # keep_indices_all를 스코어 기준 내림차순 정렬\n",
    "    #  -> top max_detections\n",
    "    final_scores = scores[keep_indices_all]\n",
    "    desc_order = np.argsort(-final_scores)\n",
    "    desc_order = desc_order[:max_detections]  # 상위 max_detections\n",
    "    final_keep = np.array(keep_indices_all)[desc_order]\n",
    "\n",
    "    return final_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def retinanet_postprocess_tflite(\n",
    "    cls_logits_list,  # list of np.array: p3->p7, shape=(1,H,W,720)\n",
    "    bbox_reg_list,    # list of np.array: p3->p7, shape=(1,H,W,36)\n",
    "    conf_thresh=0.05,\n",
    "    # iou_thresh=0.5,\n",
    "    nms_thresh=0.5,  \n",
    "    topk_candidates=1000,\n",
    "    max_detections=100\n",
    "):\n",
    "    feature_shapes = [cl.shape[1:3] for cl in cls_logits_list]  # [(80,80),(40,40),(20,20),(10,10),(5,5)]\n",
    "    anchors_list = generate_anchors_p2to4(feature_shapes)  # (사용자 정의 함수)\n",
    "\n",
    "    all_boxes   = []\n",
    "    all_scores  = []\n",
    "    all_classes = []\n",
    "\n",
    "    num_classes = 1\n",
    "    anchors_per_loc = 9\n",
    "\n",
    "    for level_i in range(len(cls_logits_list)):\n",
    "        cls_logits = cls_logits_list[level_i]  # (1,H,W,720)\n",
    "        bbox_regs  = bbox_reg_list[level_i]    # (1,H,W,36)\n",
    "        anchors_l  = anchors_list[level_i]     # (H*W*9,4)\n",
    "\n",
    "        H,W = cls_logits.shape[1], cls_logits.shape[2]\n",
    "        cls_logits_2d = cls_logits[0].reshape(H*W, 9)\n",
    "        bbox_regs_2d  = bbox_regs[0].reshape(H*W, 36)\n",
    "\n",
    "        # 시그모이드\n",
    "        cls_conf_2d = 1.0/(1.0+np.exp(-cls_logits_2d))\n",
    "\n",
    "        for a_i in range(anchors_per_loc):\n",
    "            cls_part = cls_conf_2d[:, a_i*num_classes : (a_i+1)*num_classes]  # (HW,80)\n",
    "            bbox_part= bbox_regs_2d[:, a_i*4 : (a_i+1)*4]                    # (HW,4)\n",
    "\n",
    "            # flatten => (HW*80)\n",
    "            flat_scores = cls_part.reshape(-1)\n",
    "            # threshold\n",
    "            inds = np.where(flat_scores > conf_thresh)[0]\n",
    "            \n",
    "            if len(inds)==0:\n",
    "                continue\n",
    "\n",
    "            # loc_ids / class_ids를 먼저 계산\n",
    "            class_ids = inds % num_classes\n",
    "            loc_ids   = inds // num_classes\n",
    "            selected_scores = flat_scores[inds]\n",
    "\n",
    "            # 아직 수량이 너무 많다면, 예시로 첫 5개만 찍는다\n",
    "            # print(f\"[DEBUG] level={level_i}, anchor_idx={a_i}, #selected={len(inds)}\")\n",
    "            \n",
    "            # deltas = bbox_part[loc_ids], anchors_l[loc_ids]\n",
    "            # 첫 몇개만\n",
    "            print(\"   deltas[:5] =\\n\", bbox_part[loc_ids][:5])\n",
    "            print(\"   anchors[:5] =\\n\", anchors_l[loc_ids][:5])\n",
    "\n",
    "\n",
    "            anchor_sel = anchors_l[loc_ids]  # (N,4)\n",
    "            delta_sel  = bbox_part[loc_ids]  # (N,4)\n",
    "\n",
    "            decoded = decode_boxes(delta_sel, anchor_sel)  # (N,4)\n",
    "\n",
    "            print(\"   decoded[:5] =\\n\", decoded[:5])\n",
    "            # 만약 decoded[:5] 중 y1 < 0이 있는지 확인\n",
    "            y1s = decoded[:5,1]\n",
    "            if np.any(y1s < 0):\n",
    "                print(\"   [WARNING] Some y1 are negative =>\", y1s)\n",
    "                \n",
    "\n",
    "            all_boxes.append(decoded)\n",
    "            all_scores.append(selected_scores)\n",
    "            all_classes.append(class_ids)\n",
    "\n",
    "    if len(all_boxes)==0:\n",
    "        return np.zeros((0,4)), np.array([]), np.array([])\n",
    "\n",
    "    all_boxes   = np.concatenate(all_boxes, axis=0)    # shape=(M,4)\n",
    "    all_scores  = np.concatenate(all_scores, axis=0)   # shape=(M,)\n",
    "    all_classes = np.concatenate(all_classes, axis=0)  # shape=(M,)\n",
    "\n",
    "    # topk\n",
    "    if all_scores.size > topk_candidates:\n",
    "        idx_top = np.argpartition(all_scores, -topk_candidates)[-topk_candidates:]\n",
    "        all_boxes   = all_boxes[idx_top]\n",
    "        all_scores  = all_scores[idx_top]\n",
    "        all_classes = all_classes[idx_top]\n",
    "\n",
    "    # === (바뀐 부분) 클래스별 NMS를 직접 수행 ===\n",
    "    keep = nms_classwise_np(all_boxes, all_scores, all_classes,\n",
    "                            iou_threshold=nms_thresh,\n",
    "                            max_detections=max_detections)\n",
    "\n",
    "    final_boxes   = all_boxes[keep]\n",
    "    final_scores  = all_scores[keep]\n",
    "    final_classes = all_classes[keep]\n",
    "\n",
    "    return final_boxes, final_scores, final_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   deltas[:5] =\n",
      " [[ 0.02438388  0.00164803  0.15431586  0.11322363]\n",
      " [-0.13588993  0.03981597  0.14943227  0.09400295]]\n",
      "   anchors[:5] =\n",
      " [[276.68629169  18.34314585 299.31370831  29.65685415]\n",
      " [280.          16.         296.          32.        ]]\n",
      "   decoded[:5] =\n",
      " [[275.35023738  17.68363428 301.75325088  30.35365647]\n",
      " [276.53636289  15.84855193 295.11515927  33.42555922]]\n",
      "   deltas[:5] =\n",
      " [[ 0.03122225 -0.01056861  0.3687736  -0.19439352]]\n",
      "   anchors[:5] =\n",
      " [[276.68629169  18.34314585 299.31370831  29.65685415]]\n",
      "   decoded[:5] =\n",
      " [[272.34730743  19.22295028 305.06565047  28.53790941]]\n",
      "   deltas[:5] =\n",
      " [[ 0.04116405 -0.02305134  0.11439863  0.03839124]\n",
      " [-0.1165406   0.01073337  0.15578783  0.02411323]]\n",
      "   anchors[:5] =\n",
      " [[276.68629169  18.34314585 299.31370831  29.65685415]\n",
      " [280.          16.         296.          32.        ]]\n",
      "   decoded[:5] =\n",
      " [[276.24651749  17.86095333 301.61635464  29.61745439]\n",
      " [276.78672421  15.97648337 295.48397648  32.3669844 ]]\n",
      "   deltas[:5] =\n",
      " [[-0.00231712  0.29595622  0.40937716 -0.19148967]\n",
      " [ 0.04336401 -0.04133481  0.3800171  -0.24383971]\n",
      " [-0.17260347 -0.02125466  0.4351326  -0.24825035]]\n",
      "   anchors[:5] =\n",
      " [[214.04060745  15.02030373 249.95939255  32.97969627]\n",
      " [276.68629169  18.34314585 299.31370831  29.65685415]\n",
      " [280.          16.         296.          32.        ]]\n",
      "   decoded[:5] =\n",
      " [[204.87209056  21.90040576 258.96145347  36.72998225]\n",
      " [272.43707128  19.09956439 305.52535979  27.96513561]\n",
      " [272.87700105  17.41860858 297.59968781  29.90124217]]\n",
      "=== Detection Results ===\n",
      "0: class=0, score=0.614, box=[276.24651749  17.86095333 301.61635464  29.61745439]\n",
      "1: class=0, score=0.106, box=[204.87209056  21.90040576 258.96145347  36.72998225]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "############################\n",
    "# 7) 후처리 실행\n",
    "############################\n",
    "final_boxes, final_scores, final_classes = retinanet_postprocess_tflite(\n",
    "    cls_logits_list, bbox_reg_list,\n",
    "    conf_thresh=0.05,\n",
    "    nms_thresh=0.3,\n",
    "    topk_candidates=1000,\n",
    "    max_detections=3\n",
    ")\n",
    "\n",
    "print(\"=== Detection Results ===\")\n",
    "for i in range(len(final_boxes)):\n",
    "    box = final_boxes[i]    # (x1,y1,x2,y2)\n",
    "    score = final_scores[i]\n",
    "    clsid = final_classes[i]\n",
    "    print(f\"{i}: class={clsid}, score={score:.3f}, box={box}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_boxes_to_image(boxes, img_width, img_height):\n",
    "    \"\"\"\n",
    "    boxes: np.array of shape (N,4) [x1,y1,x2,y2]\n",
    "    \"\"\"\n",
    "    boxes[:,0] = np.maximum(boxes[:,0], 0.0)            # x1 >= 0\n",
    "    boxes[:,1] = np.maximum(boxes[:,1], 0.0)            # y1 >= 0\n",
    "    boxes[:,2] = np.minimum(boxes[:,2], img_width)      # x2 <= width\n",
    "    boxes[:,3] = np.minimum(boxes[:,3], img_height)     # y2 <= height\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def visualize_detections(\n",
    "    image_bgr, \n",
    "    final_boxes,     # shape=(N,4)\n",
    "    final_scores,    # shape=(N,)\n",
    "    final_classes,   # shape=(N,)\n",
    "    class_names=None # 예: [\"person\", \"car\", ...] \n",
    "):\n",
    "    \"\"\"\n",
    "    image_bgr: 원본 또는 리사이즈된 BGR 이미지 (H,W,3)\n",
    "    final_boxes: (x1,y1,x2,y2), float\n",
    "    final_scores: confidence\n",
    "    final_classes: 정수 클래스 ID\n",
    "    class_names: 클래스 이름 리스트 (옵션)\n",
    "    \"\"\"\n",
    "    img_h, img_w = image_bgr.shape[:2]\n",
    "    \n",
    "    # 1) 박스를 이미지 범위에 클리핑\n",
    "    boxes_clipped = clip_boxes_to_image(final_boxes.copy(), img_w, img_h)\n",
    "\n",
    "    # 2) 박스 그려넣기\n",
    "    for i in range(len(boxes_clipped)):\n",
    "        box = boxes_clipped[i]\n",
    "        score = final_scores[i]\n",
    "        clsid = final_classes[i]\n",
    "        \n",
    "        x1, y1, x2, y2 = box.astype(int)  # 정수 좌표 변환\n",
    "        print(\"Draw box =>\", x1, y1, x2, y2)\n",
    "        \n",
    "        # 선택적으로, 너무 작은 박스는 건너뛸 수도 있음\n",
    "        if (x2 - x1) < 1 or (y2 - y1) < 1:\n",
    "            continue\n",
    "\n",
    "        # 색상(임시): 클래스 ID에 따라 임의 색 지정\n",
    "        color = (0, 255, 255)  # 노랑(BGR) 등\n",
    "        # 혹은 clsid를 이용해 여러 색 중 선택할 수도 있음\n",
    "        \n",
    "        # 사각형 그리기\n",
    "        cv2.rectangle(\n",
    "            image_bgr,\n",
    "            (x1, y1),\n",
    "            (x2, y2),\n",
    "            color,\n",
    "            thickness=2\n",
    "        )\n",
    "        \n",
    "        # 라벨 텍스트\n",
    "        if class_names is not None and 0 <= clsid < len(class_names):\n",
    "            cls_name = class_names[clsid]\n",
    "        else:\n",
    "            cls_name = f\"cls:{clsid}\"\n",
    "        \n",
    "        label_text = f\"{cls_name} {score:.2f}\"\n",
    "        print(label_text)\n",
    "        \n",
    "        # 텍스트 표시 위치 (x1,y1-5) 등\n",
    "        cv2.putText(\n",
    "            image_bgr,\n",
    "            label_text,\n",
    "            (x2, max(y2 - 5, 0)),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.6,      # 폰트 스케일\n",
    "            color,\n",
    "            2         # 두께\n",
    "        )\n",
    "    \n",
    "    return image_bgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_boxes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m draw_img \u001b[38;5;241m=\u001b[39m resized_bgr\u001b[38;5;241m.\u001b[39mcopy()  \u001b[38;5;66;03m# 원본 유지\u001b[39;00m\n\u001b[1;32m      2\u001b[0m draw_img \u001b[38;5;241m=\u001b[39m visualize_detections(\n\u001b[1;32m      3\u001b[0m     draw_img,\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mfinal_boxes\u001b[49m, final_scores, final_classes, class_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHidden_lens\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMachine_Mini\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMachine_Plug\u001b[39m\u001b[38;5;124m\"\u001b[39m] \n\u001b[1;32m      5\u001b[0m     \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# index=2일 때 \"Car\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(final_classes)\n\u001b[1;32m     11\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetection_result_1.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, draw_img)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_boxes' is not defined"
     ]
    }
   ],
   "source": [
    "draw_img = resized_bgr.copy()  # 원본 유지\n",
    "draw_img = visualize_detections(\n",
    "    draw_img,\n",
    "    final_boxes, final_scores, final_classes, class_names = [\"Hidden_lens\", \"Machine_Mini\", \"Machine_Plug\"] \n",
    "    \n",
    "# index=2일 때 \"Car\"\n",
    ")\n",
    "\n",
    "print(final_classes)\n",
    "\n",
    "cv2.imwrite(\"detection_result_1.jpg\", draw_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMv6HxF2mk/zSsw18Qb5eCq",
   "collapsed_sections": [
    "zqcMW3MXTp3C"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "on2tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
