{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2fcaa7c-73e3-4ab8-83a2-9f2d618d8220",
   "metadata": {},
   "outputs": [],
   "source": [
    "## watch -n 1 nvidia-smi\n",
    "# 터미널에 실행해서 gpu 보면서 실행시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a1c336-d64e-4f8e-b69f-47454d5791a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1. Import 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "667856a3-8f36-450b-9d61-1d1d86cf521e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/onnxscript/converter.py:823: FutureWarning: 'onnxscript.values.Op.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n",
      "/opt/conda/lib/python3.11/site-packages/onnxscript/converter.py:823: FutureWarning: 'onnxscript.values.OnnxFunction.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n"
     ]
    }
   ],
   "source": [
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "# 1) 리스트 형태로 반환된 Catalog 이름들에서 remove를 이용해 제거\n",
    "dataset_list = DatasetCatalog.list()\n",
    "metadata_list = MetadataCatalog.list()\n",
    "\n",
    "if \"totaltext_train\" in dataset_list:\n",
    "    dataset_list.remove(\"totaltext_train\")\n",
    "    print(\"'totaltext_train' removed from DatasetCatalog list\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aab63d9-e176-42d0-a948-6a215f42f821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/snukdt/fcos_model/AdelaiDet/adet/modeling/MEInst/MaskEncoding.py:9: FutureWarning: Decorating classes is deprecated and will be disabled in future versions. You should only decorate functions or methods. To preserve the current behavior of class decoration, you can directly decorate the `__init__` method and nothing else.\n",
      "  @torch.no_grad()\n"
     ]
    }
   ],
   "source": [
    "import sys, os, distutils.core\n",
    "import random\n",
    "import torch\n",
    "import math\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import logging\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import LazyConfig, instantiate, get_cfg\n",
    "from detectron2.data import (\n",
    "    MetadataCatalog,\n",
    "    DatasetCatalog,\n",
    "    build_detection_train_loader,\n",
    "    build_detection_test_loader\n",
    ")\n",
    "from detectron2.engine import SimpleTrainer, DefaultPredictor, hooks, DefaultTrainer, HookBase\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset, DatasetEvaluators\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.utils.events import CommonMetricPrinter, JSONWriter, TensorboardXWriter, EventStorage\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.structures import BoxMode\n",
    "import detectron2.data\n",
    "from detectron2.data import detection_utils as utils\n",
    "from AdelaiDet.adet.data.augmentation import RandomCropWithInstance\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "\n",
    "from adet.config import get_cfg as get_adet_cfg  # AdelaiDet 전용 get_cfg\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Seed 설정 함수\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# 데이터셋을 train, validation, test로 나누기\n",
    "def split_dataset(dataset, train_size, val_size, test_size, seed=42):\n",
    "    random.seed(seed)  # 무작위성을 고정하기 위한 시드 설정\n",
    "    random.shuffle(dataset)  # 데이터를 무작위로 섞음\n",
    "    return (\n",
    "        dataset[:train_size], \n",
    "        dataset[train_size:train_size + val_size], \n",
    "        dataset[train_size + val_size:]  # 남은 데이터를 테스트로 할당\n",
    "    )\n",
    "\n",
    "# Set GPU device\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62771e7d-1fa3-4ee0-9368-b45e792dae43",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2. 이미지 등록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e567d1d9-5dc0-48b3-8e26-92c848bef34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class 1개로만 할 때 적용\n",
    "def get_custom_dicts(img_dir, json_file):\n",
    "    with open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    images = {img[\"id\"]: img for img in data[\"images\"]}\n",
    "    annotations = {}\n",
    "\n",
    "    # 유지하고 싶은 클래스: Hiddenlens(category_id=2)\n",
    "    # 매핑: 2 -> 0\n",
    "    desired_category = 0\n",
    "\n",
    "    for ann in data[\"annotations\"]:\n",
    "        image_id = ann[\"image_id\"]\n",
    "        # category_id가 2가 아닌 경우 모두 제외\n",
    "        if ann[\"category_id\"] != desired_category:\n",
    "            continue\n",
    "\n",
    "        # 남은 category_id=2를 0으로 remap\n",
    "        ann_copy = ann.copy()\n",
    "        annotations.setdefault(image_id, []).append(ann_copy)\n",
    "\n",
    "    dataset_dicts = []\n",
    "    for image_id, img_info in images.items():\n",
    "        filtered_annotations = [\n",
    "            {\n",
    "                \"bbox\": ann[\"bbox\"],\n",
    "                \"bbox_mode\": BoxMode.XYWH_ABS,\n",
    "                \"category_id\": ann[\"category_id\"]\n",
    "            }\n",
    "            for ann in annotations.get(image_id, [])\n",
    "        ]\n",
    "\n",
    "        if filtered_annotations:\n",
    "            record = {\n",
    "                \"file_name\": os.path.join(img_dir, img_info[\"file_name\"]),\n",
    "                \"image_id\": image_id,\n",
    "                \"height\": img_info[\"height\"],\n",
    "                \"width\": img_info[\"width\"],\n",
    "                \"annotations\": filtered_annotations,\n",
    "            }\n",
    "            dataset_dicts.append(record)\n",
    "\n",
    "    # 이 구조 Detectron2에 학습에 사용할 dataset 정보\n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285d6e63-4134-47f5-a64d-01c219d7734e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 3. Crop 적용 Custom Mapper (5~35 pixel)\n",
    "- 320 x 320으로 Resize되었을 때 불법 카메라가 5~35 pixel 범위로 들어올 수 있도록 설정\n",
    "    \n",
    "- 원본 이미지에서 45 pixel 이하인 경우에는 (480, 640)으로 Crop 적용\n",
    "- 원본 이미지에서 45 pixel 이상인 경우에는 5 ~ 35 pixel 범위로 들어올 수 있도록 Crop할 Width 범위를 구해서 중간값 적용(이 부분은 중간값 적용하지 않고, 다른 방법들 적용이 가능합니다. 저희는 중간 값을 적용했습니다.)\n",
    "    - 정확한 수식은 cropW_min에서 35를 나눠주고, cropW_max에선느 5를 나눠줘야 되지만, 대략적으로 정규분포 형태를 띄게 하려고 각각 30, 10으로 나눠줬습니다.\n",
    "\n",
    "- CROP 적용 이후 Dataset에서 0 pixel로 기록된 Hiddenlens가 있는데, 이는 한 개의 이미지에 2개 이상의 Hiddenlens가 있어 CROP 과정에서 잘려서 0 Pixel로 기록된 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aff8a8d-d3a9-4d4d-91d5-6d136f438cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.structures import BoxMode\n",
    "\n",
    "def custom_mapper(dataset_dict):\n",
    "    \"\"\"\n",
    "    이미지를 크롭하고, bbox를 XYWH 형태로 변환한 뒤\n",
    "    dataset_dict['annotations']와 dataset_dict[\"image\"] 등을 업데이트.\n",
    "\n",
    "    - 폭 45 이상인 Hiddenlens가 하나라도 있으면 특수 크롭 (3:4 비율)\n",
    "    - 아니면 (640,480) 크기로 RandomCropWithInstance\n",
    "    \"\"\"\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)\n",
    "    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
    "\n",
    "    annos = dataset_dict[\"annotations\"]\n",
    "    boxes_xyxy = [] # 변환된 모든 바운딩 박스를 저장하는 리스트\n",
    "\n",
    "    # Hiddenlens 폭 리스트 (category_id=0 인 bbox)\n",
    "    hiddenlens_bbox_widths = []\n",
    "\n",
    "    # -- A. Hiddenlens(카테고리=0) bbox 폭 계산 --\n",
    "    for anno in annos:\n",
    "        # (1) category=0 이면 폭 계산\n",
    "        if anno[\"category_id\"] == 0:\n",
    "            # bbox를 XYWH -> XYXY로 변환\n",
    "            box_xyxy = BoxMode.convert(anno[\"bbox\"], BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\n",
    "            w_lens = box_xyxy[2] - box_xyxy[0]\n",
    "            hiddenlens_bbox_widths.append(w_lens)\n",
    "\n",
    "        # (2) 모든 bbox XYXY 변환 (transform 에 쓰기 위함)\n",
    "        box_xyxy_all = BoxMode.convert(anno[\"bbox\"], BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\n",
    "        boxes_xyxy.append(box_xyxy_all)\n",
    "\n",
    "    # -- B. \"폭 45 이상\"인 Hiddenlens가 하나라도 있으면 특수(수동) 크롭 --\n",
    "    #     아니면 (모두 45 미만이거나 없음) -> 기존 로직(RandomCropWithInstance) --\n",
    "    apply_special_crop = any(w >= 45 for w in hiddenlens_bbox_widths)\n",
    "\n",
    "    # 이미지 높이, 너비\n",
    "    orig_h, orig_w = image.shape[:2]\n",
    "\n",
    "    if apply_special_crop:\n",
    "        # ------------------------------------------------\n",
    "        # (1) 특수 크롭 (3:4 비율 유지)\n",
    "        # ------------------------------------------------\n",
    "        w_lens_max = max(hiddenlens_bbox_widths)\n",
    "\n",
    "        # cropW 범위 계산\n",
    "        # Hiddenlens의 폭(w_lens_max)에 따라 크롭 폭을 결정\n",
    "        cropW_min = (320.0 * w_lens_max) / 30.0\n",
    "        cropW_max = (320.0 * w_lens_max) / 10.0\n",
    "\n",
    "        # clip\n",
    "        cropW_min = max(1, min(cropW_min, orig_w))\n",
    "        cropW_max = max(1, min(cropW_max, orig_w))\n",
    "\n",
    "        if cropW_min > cropW_max:\n",
    "            # 범위 말이 안되면 fallback\n",
    "            cropW = min(orig_w, 480)\n",
    "        else:\n",
    "            # 중간값 적용(여기서 random.uniform도 적용 가능)\n",
    "            cropW = (cropW_min + cropW_max) * 0.5\n",
    "\n",
    "        # 3:4 비율 -> 실제 휴대폰에서 이미지를 받는 비율인 3:4 맞춰주기\n",
    "        cropH = (4.0 / 3.0) * cropW\n",
    "\n",
    "        # 만약 cropH이 원본보다 크면 clip\n",
    "        if cropH > orig_h:\n",
    "            ratio = orig_h / cropH\n",
    "            cropH = orig_h\n",
    "            cropW = cropW * ratio\n",
    "\n",
    "        cropW = int(round(cropW))\n",
    "        cropH = int(round(cropH))\n",
    "\n",
    "        # RandomCropWithInstance 적용(객체 중심의 Crop 기법)\n",
    "        # AdelaiDet에서 제공\n",
    "        from adet.data.augmentation import RandomCropWithInstance\n",
    "        special_crop = RandomCropWithInstance(\n",
    "            crop_type='absolute',\n",
    "            crop_size=(cropH, cropW),\n",
    "            crop_instance=True\n",
    "        )\n",
    "        transform = special_crop.get_transform(image, boxes_xyxy)\n",
    "\n",
    "        image_cropped = transform.apply_image(image)\n",
    "        image_cropped = image_cropped.copy()\n",
    "\n",
    "        annos_new = []\n",
    "        for a in annos:\n",
    "            # 기본 BBox를 XYXY로 변환\n",
    "            box_xyxy = BoxMode.convert(a[\"bbox\"], BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\n",
    "            # BBox가 크롭된 부분을 기준으로 새로운 좌표를 계산\n",
    "            box_xyxy_2d = np.array([box_xyxy])\n",
    "            box_xyxy_2d = transform.apply_box(box_xyxy_2d) # 변환 적용\n",
    "            box_xyxy_out = box_xyxy_2d[0] # 변환된 BBox\n",
    "\n",
    "            # 유효 bbox 검사\n",
    "            if (box_xyxy_out[2] > box_xyxy_out[0]) and (box_xyxy_out[3] > box_xyxy_out[1]):\n",
    "                # 다시 XYWH로 변환\n",
    "                box_xywh_2d = BoxMode.convert(\n",
    "                    box_xyxy_2d, BoxMode.XYXY_ABS, BoxMode.XYWH_ABS\n",
    "                )\n",
    "                a_new = copy.deepcopy(a)\n",
    "                a_new[\"bbox\"] = box_xywh_2d[0].tolist()\n",
    "                a_new[\"bbox_mode\"] = BoxMode.XYWH_ABS  # ← XYWH 모드로 명시\n",
    "                annos_new.append(a_new)\n",
    "\n",
    "        new_h, new_w = image_cropped.shape[:2]\n",
    "        dataset_dict[\"annotations\"] = annos_new\n",
    "        dataset_dict[\"height\"] = new_h\n",
    "        dataset_dict[\"width\"]  = new_w\n",
    "\n",
    "        # (C,H,W) 순서로 변환\n",
    "        image_chw = image_cropped.transpose(2, 0, 1).copy()\n",
    "        dataset_dict[\"image\"] = torch.as_tensor(image_chw, dtype=torch.float32)\n",
    "\n",
    "        # 최종 instances\n",
    "        annos_transformed = [\n",
    "            utils.transform_instance_annotations(\n",
    "                obj, transforms=[], image_size=(new_h, new_w)\n",
    "            )\n",
    "            for obj in annos_new\n",
    "        ]\n",
    "        from detectron2.data import detection_utils\n",
    "        dataset_dict[\"instances\"] = detection_utils.annotations_to_instances(\n",
    "            annos_transformed, (new_h, new_w)\n",
    "        )\n",
    "        return dataset_dict\n",
    "\n",
    "    else:\n",
    "        # ------------------------------------------------\n",
    "        # (2) 폭 45 미만 → 기존 RandomCropWithInstance\n",
    "        # ------------------------------------------------\n",
    "        from adet.data.augmentation import RandomCropWithInstance\n",
    "        crop_augment = RandomCropWithInstance(\n",
    "            crop_type='absolute', \n",
    "            crop_size=(640, 480),\n",
    "            crop_instance=True\n",
    "        )\n",
    "        transform = crop_augment.get_transform(image, boxes_xyxy)\n",
    "        image_cropped = transform.apply_image(image)\n",
    "        image_cropped = image_cropped.copy()\n",
    "\n",
    "        annos_new = []\n",
    "        for a in annos:\n",
    "            box_xyxy = BoxMode.convert(a[\"bbox\"], BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\n",
    "            box_xyxy_2d = np.array([box_xyxy])\n",
    "            box_xyxy_2d = transform.apply_box(box_xyxy_2d)\n",
    "            box_xyxy_out = box_xyxy_2d[0]\n",
    "\n",
    "            # 유효 bbox 검사\n",
    "            if (box_xyxy_out[2] > box_xyxy_out[0]) and (box_xyxy_out[3] > box_xyxy_out[1]):\n",
    "                # XYWH 재변환\n",
    "                box_xywh_2d = BoxMode.convert(\n",
    "                    box_xyxy_2d, BoxMode.XYXY_ABS, BoxMode.XYWH_ABS\n",
    "                )\n",
    "                a_new = copy.deepcopy(a)\n",
    "                a_new[\"bbox\"] = box_xywh_2d[0].tolist()\n",
    "                a_new[\"bbox_mode\"] = BoxMode.XYWH_ABS  # ← XYWH 모드 명시\n",
    "                annos_new.append(a_new)\n",
    "\n",
    "        new_h, new_w = image_cropped.shape[:2]\n",
    "        dataset_dict[\"annotations\"] = annos_new\n",
    "        dataset_dict[\"height\"] = new_h\n",
    "        dataset_dict[\"width\"]  = new_w\n",
    "\n",
    "        image_chw = image_cropped.transpose(2, 0, 1).copy()\n",
    "        dataset_dict[\"image\"] = torch.as_tensor(image_chw, dtype=torch.float32)\n",
    "\n",
    "        annos_transformed = [\n",
    "            utils.transform_instance_annotations(\n",
    "                obj, transforms=[], image_size=(new_h, new_w)\n",
    "            )\n",
    "            for obj in annos_new\n",
    "        ]\n",
    "        from detectron2.data import detection_utils\n",
    "        dataset_dict[\"instances\"] = detection_utils.annotations_to_instances(\n",
    "            annos_transformed, (new_h, new_w)\n",
    "        )\n",
    "        return dataset_dict\n",
    "\n",
    "# 크롭 적용\n",
    "class CustomTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        return build_detection_train_loader(cfg, mapper=custom_mapper)\n",
    "\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name):\n",
    "        return COCOEvaluator(dataset_name, cfg, True, output_dir=cfg.OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3341cb6b-5db8-4985-902d-098420f72c61",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 4. 흔들리거나 식별이 어려운 이미지 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e73cc36-801b-4240-96d1-2e09fa4a6346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n"
     ]
    }
   ],
   "source": [
    "# 삭제할 인덱스 정의\n",
    "delete_indices = set()\n",
    "\n",
    "# 첫 번째 그룹: +1 적용\n",
    "delete_indices.update([178 + 1, 249 + 1, 263 + 1, 63 + 1, 340 + 1, 357 + 1, 358 + 1, \n",
    "                       359 + 1, 360 + 1, 367 + 1, 413 + 1, 481 + 1,\n",
    "                       20 + 1, 35 + 1, 53 + 1, 54 + 1, 58 + 1, 61 + 1, 136 + 1, 147 + 1, \n",
    "                       152 + 1, 215 + 1, 247 + 1, 248 + 1, 255 + 1, 262 + 1, 268 + 1, \n",
    "                       269 + 1, 299 + 1, 332 + 1, 355 + 1, 390 + 1, 399 + 1, 483 + 1, 492 + 1])\n",
    "\n",
    "# 두 번째 그룹: +500 적용\n",
    "delete_indices.update([\n",
    "    205 + 500, 217 + 500, 247 + 500, 474 + 500, 344 + 500, \n",
    "    362 + 500, 481 + 500, 499 + 500,\n",
    "    17 + 500, 30 + 500, 34 + 500, 55 + 500, 58 + 500, 74 + 500, \n",
    "    106 + 500, 148 + 500, 160 + 500, 199 + 500, 211 + 500, 260 + 500, \n",
    "    263 + 500, 264 + 500, 281 + 500, 285 + 500, 288 + 500, 321 + 500, \n",
    "    359 + 500, 372 + 500, 377 + 500])\n",
    "\n",
    "# 세 번째 그룹: +1000 적용\n",
    "delete_indices.update([\n",
    "    236 + 1000, 245 + 1000, 267 + 1000, 314 + 1000, 334 + 1000, \n",
    "    346 + 1000, 353 + 1000, 382 + 1000, 483 + 1000, 499 + 1000,\n",
    "    14 + 1000, 19 + 1000, 22 + 1000, 25 + 1000, 43 + 1000, 47 + 1000, \n",
    "    54 + 1000, 96 + 1000, 106 + 1000, 117 + 1000, 138 + 1000, 140 + 1000, \n",
    "    141 + 1000, 149 + 1000, 177 + 1000, 189 + 1000, 197 + 1000, 198 + 1000, \n",
    "    204 + 1000, 205 + 1000, 231 + 1000, 232 + 1000, 234 + 1000, 235 + 1000, \n",
    "    277 + 1000, 280 + 1000, 294 + 1000, 348 + 1000, 349 + 1000, 358 + 1000, \n",
    "    362 + 1000, 419 + 1000, 485 + 1000, 492 + 1000, 494 + 1000, 498 + 1000])\n",
    "\n",
    "print(len(delete_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf53be2-9855-4e46-b57d-8ea2755ba22a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 5. Crop 적용 후 새로운 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c147c8e-3a4d-4b36-84d3-2ec6c2a20e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Cropped dataset & annotations saved in: ./cropped_output\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# detectron2 관련 임포트\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.data import detection_utils as utils\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# (1) Dataset 읽어오기 (get_custom_dicts 등)\n",
    "# ---------------------------------------------------\n",
    "json_file = \"./instances_default.json\"\n",
    "img_dir   = \"./images\"\n",
    "all_data  = get_custom_dicts(img_dir, json_file)\n",
    "all_data = [d for d in all_data if d[\"image_id\"] not in delete_indices]\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# (2) 크롭된 이미지를 output 디렉토리에 저장 + 새 어노테이션 JSON 생성\n",
    "# ---------------------------------------------------\n",
    "def save_cropped_dataset(dataset_dicts, output_dir):\n",
    "    \"\"\"\n",
    "    dataset_dicts: Detectron2에서 사용하는 dataset_dict 형식 (list of dict)\n",
    "    output_dir   : 크롭된 이미지를 저장할 폴더 경로\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # COCO JSON 형식을 구성하기 위한 변수들\n",
    "    new_images = []\n",
    "    new_annotations = []\n",
    "    next_ann_id = 1  # 새로 매길 annotation id\n",
    "    category_id_map = {}  # category id 매핑 (보통은 1개 클래스라면 그대로 0 또는 1 등으로 사용)\n",
    "\n",
    "    # categories (예: 클래스가 1개라면 아래처럼)\n",
    "    categories = [\n",
    "        {\"id\": 0, \"name\": \"Hiddenlens\"}\n",
    "    ]\n",
    "\n",
    "    for idx, dataset_dict in enumerate(dataset_dicts):\n",
    "        # custom_mapper 를 호출해 크롭 + bbox 재계산\n",
    "        transformed_dict = custom_mapper(dataset_dict)\n",
    "\n",
    "        # (2-1) 이미지 추출 (torch -> numpy)\n",
    "        cropped_img_chw = transformed_dict[\"image\"]  # (C,H,W)\n",
    "        cropped_img_hwc = cropped_img_chw.permute(1, 2, 0).numpy()  # (H,W,C)\n",
    "\n",
    "        # BGR -> 저장 시 그대로 써도 되고, 혹은 RGB->BGR 변환 여부 확인\n",
    "        # 여기서는 custom_mapper에서 utils.read_image(image, format=\"BGR\")를 썼으므로\n",
    "        # cropped_img_hwc는 이미 BGR일 가능성이 높음. 필요한 경우 변환\n",
    "        # cropped_img_hwc = cv2.cvtColor(cropped_img_hwc, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # (2-2) 새 파일명 지정 후 저장\n",
    "        # ex) \"cropped_00001.jpg\" 와 같이 저장\n",
    "        new_filename = f\"cropped_{idx:05d}.jpg\"\n",
    "        out_path = os.path.join(output_dir, new_filename)\n",
    "        cv2.imwrite(out_path, cropped_img_hwc)\n",
    "\n",
    "        # (2-3) COCO JSON용 images 정보 추가\n",
    "        new_image_id = idx + 1  # 새 image_id (1부터 부여)\n",
    "        new_w = transformed_dict[\"width\"]\n",
    "        new_h = transformed_dict[\"height\"]\n",
    "        new_images.append({\n",
    "            \"id\": new_image_id,\n",
    "            \"file_name\": new_filename,\n",
    "            \"width\": new_w,\n",
    "            \"height\": new_h\n",
    "        })\n",
    "\n",
    "        # (2-4) COCO JSON용 annotations 정보 추가\n",
    "        #       custom_mapper를 거친 후의 bbox가 dataset_dict[\"annotations\"]에 있음\n",
    "        annos = transformed_dict[\"annotations\"]\n",
    "        for anno in annos:\n",
    "            # anno[\"bbox\"]는 XYWH_ABS 형태\n",
    "            # category_id도 mapper에서 이미 0으로 remap 되어있음 (Hiddenlens)\n",
    "            new_annotations.append({\n",
    "                \"id\": next_ann_id,\n",
    "                \"image_id\": new_image_id,\n",
    "                \"category_id\": anno[\"category_id\"],\n",
    "                \"bbox\": anno[\"bbox\"].tolist(),  # [x, y, w, h]\n",
    "                \"area\": anno[\"bbox\"][2] * anno[\"bbox\"][3],  # w*h\n",
    "                \"iscrowd\": 0\n",
    "            })\n",
    "            next_ann_id += 1\n",
    "\n",
    "    # (2-5) 최종 COCO json 만들기\n",
    "    # 필요한 필드만 간단히 생성. (라이센스 정보, segmentations 등은 생략 예시)\n",
    "    coco_output = {\n",
    "        \"images\": new_images,\n",
    "        \"annotations\": new_annotations,\n",
    "        \"categories\": categories,\n",
    "    }\n",
    "\n",
    "    # JSON 저장\n",
    "    with open(os.path.join(output_dir, \"cropped_annotations.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(coco_output, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"Done! Cropped dataset & annotations saved in: {output_dir}\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 실제 실행\n",
    "# ---------------------------------------------------\n",
    "output_dir = \"./cropped_output\"\n",
    "save_cropped_dataset(all_data, output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2ada41-cf8f-413f-85fc-4f899a3be3f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 6. 새롭게 만들어진 파일을 이용해 변환 잘 되었는지 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0685e956-7614-45b1-8eb2-6a89a2b7084a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------- 사용자 환경에 맞게 설정 ---------------\n",
    "annotation_file = \"./cropped_output/cropped_annotations_xywh.json\"\n",
    "images_dir      = \"./cropped_output\"\n",
    "hiddenlens_id   = 0   # \"Hiddenlens\" 클래스 id\n",
    "# -----------------------------------------------------\n",
    "\n",
    "# (1) JSON 로드\n",
    "with open(annotation_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "# images, annotations를 딕셔너리로 매핑\n",
    "images_info = {img[\"id\"]: img for img in dataset[\"images\"]}\n",
    "\n",
    "annotations_by_image = {}\n",
    "for ann in dataset[\"annotations\"]:\n",
    "    image_id = ann[\"image_id\"]\n",
    "    annotations_by_image.setdefault(image_id, []).append(ann)\n",
    "\n",
    "# (2) 이미지별로 로드 & 시각화\n",
    "for image_id, image_meta in images_info.items():\n",
    "    file_name = image_meta[\"file_name\"]\n",
    "    file_path = os.path.join(images_dir, file_name)\n",
    "\n",
    "    # OpenCV로 이미지 읽기 (BGR)\n",
    "    image_bgr = cv2.imread(file_path)\n",
    "    if image_bgr is None:\n",
    "        print(f\"[WARN] Could not load image: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    # OpenCV에서 shape (H, W, C) 획득\n",
    "    h_img, w_img = image_bgr.shape[:2]\n",
    "\n",
    "    # 화면(터미널)에 이미지/크기 정보 출력\n",
    "    print(f\"---- Image ID: {image_id} ----\")\n",
    "    print(f\" file_name: {file_name}\")\n",
    "    print(f\" Image Width={w_img}, Height={h_img}\")\n",
    "\n",
    "    # Bounding Box 시각화를 위해, 이미지를 복사해서 사용\n",
    "    vis_image_bgr = image_bgr.copy()\n",
    "\n",
    "    # 해당 이미지의 어노테이션들\n",
    "    if image_id not in annotations_by_image:\n",
    "        # 어노테이션이 없는 경우 바로 넘어감\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(cv2.cvtColor(vis_image_bgr, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"Image ID {image_id}: No Annotations\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "        continue\n",
    "\n",
    "    for ann in annotations_by_image[image_id]:\n",
    "        # bbox = [x, y, w, h], XYWH 형식\n",
    "        x, y, w_bb, h_bb = ann[\"bbox\"]\n",
    "        x2 = x + w_bb \n",
    "        y2 = y + h_bb\n",
    "        \n",
    "        # 초록색 사각형으로 표시\n",
    "        cv2.rectangle(\n",
    "            vis_image_bgr,\n",
    "            (int(x), int(y)),\n",
    "            (int(x2), int(y2)),\n",
    "            color=(0, 255, 0),\n",
    "            thickness=2\n",
    "        )\n",
    "\n",
    "        # Hiddenlens 클래스면 폭, 높이만 출력\n",
    "        if ann[\"category_id\"] == hiddenlens_id:\n",
    "            print(f\"  [Hiddenlens] BBox => width={w_bb:.1f}, height={h_bb:.1f}\")\n",
    "\n",
    "    # (3) Matplotlib으로 시각화 (BGR→RGB 변환)\n",
    "    vis_image_rgb = cv2.cvtColor(vis_image_bgr, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(vis_image_rgb)\n",
    "    plt.title(f\"Image ID {image_id}: {file_name}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bd39a5-251f-4850-a200-e38d33d07fdd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 7. 기존 Dataset의 Json 파일과 같은 형식으로 가져오기\n",
    "- 완전히 동일한 형식으로 가져오지 않고 학습에 필요한 부분만 Json 파일로 만들었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21ef2860-eb9b-4015-ace1-4d8c2920d09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Saved to: ./cropped_output/cropped_annotations_xywh.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def convert_bbox_xyxy_to_xywh(json_path, output_path=None):\n",
    "    \"\"\"\n",
    "    cropped_annotations.json 안의 모든 bbox가 [x1, y1, x2, y2] 인 것으로 가정.\n",
    "    이를 [x, y, w, h] 으로 바꾸고, area를 다시 계산해서 저장.\n",
    "\n",
    "    Args:\n",
    "        json_path   : 원본 JSON 경로 (예: \"./cropped_annotations.json\")\n",
    "        output_path : 변환 완료 후 저장할 JSON 경로\n",
    "                     None 이면, 원본 파일에 덮어씀\n",
    "    \"\"\"\n",
    "    if output_path is None:\n",
    "        # 덮어쓰지 않으려면 다른 이름으로 저장하세요.\n",
    "        output_path = json_path\n",
    "\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    annotations = data.get(\"annotations\", [])\n",
    "\n",
    "    for ann in annotations:\n",
    "        bbox = ann.get(\"bbox\", None)\n",
    "        if bbox is None or len(bbox) < 4:\n",
    "            continue\n",
    "\n",
    "        # bbox = [x1, y1, x2, y2] 이라고 가정\n",
    "        x1 = bbox[0]\n",
    "        y1 = bbox[1]\n",
    "        x2 = bbox[2]\n",
    "        y2 = bbox[3]\n",
    "\n",
    "        # 새로 w, h 계산\n",
    "        w = x2 - x1\n",
    "        h = y2 - y1\n",
    "\n",
    "        # bbox 업데이트: [x, y, w, h] 로 변환\n",
    "        ann[\"bbox\"] = [x1, y1, w, h]\n",
    "\n",
    "        # area 다시 계산\n",
    "        # 만약 음수(잘못된 bbox)일 때는 0 처리\n",
    "        if w < 0 or h < 0:\n",
    "            new_area = 0\n",
    "        else:\n",
    "            new_area = w * h\n",
    "\n",
    "        ann[\"area\"] = new_area\n",
    "\n",
    "    # 업데이트 완료 후 저장\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Done! Saved to: {output_path}\")\n",
    "\n",
    "\n",
    "# 실제 사용 예시\n",
    "if __name__ == \"__main__\":\n",
    "    # 원본 JSON 파일 경로\n",
    "    json_input = \"./cropped_output/cropped_annotations.json\"\n",
    "    # 결과 저장 경로 (원본에 덮어쓰려면 json_input과 동일하게 설정 가능)\n",
    "    json_output = \"./cropped_output/cropped_annotations_xywh.json\"\n",
    "\n",
    "    convert_bbox_xyxy_to_xywh(json_input, json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddd6c3a0-1bf7-42de-9156-ccb0f34be2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated categories[0] in: ./cropped_output/cropped_annotations_xywh.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def update_categories(json_path, output_path=None):\n",
    "    \"\"\"\n",
    "    cropped_annotations.json 파일을 로드하여,\n",
    "    categories[0]에 {id=1, name='Hiddenlens', supercategory=''} 를 설정한 뒤 저장한다.\n",
    "    \n",
    "    :param json_path: (str) 수정할 JSON 파일 경로\n",
    "    :param output_path: (str) 수정 결과를 저장할 경로 (None이면 원본에 덮어쓰기)\n",
    "    \"\"\"\n",
    "    if output_path is None:\n",
    "        output_path = json_path  # 덮어쓰기\n",
    "\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # categories 첫 번째 항목 수정\n",
    "    if \"categories\" in data and len(data[\"categories\"]) > 0:\n",
    "        data[\"categories\"][0][\"id\"] = 1\n",
    "        data[\"categories\"][0][\"name\"] = \"Hiddenlens\"\n",
    "        data[\"categories\"][0][\"supercategory\"] = \"\"\n",
    "\n",
    "    # 수정된 JSON 저장\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"Updated categories[0] in: {output_path}\")\n",
    "\n",
    "# 사용 예시\n",
    "if __name__ == \"__main__\":\n",
    "    json_file = \"./cropped_output/cropped_annotations_xywh.json\"\n",
    "    update_categories(json_file)  # 원본에 덮어쓰기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b09f1864-179a-48ba-bfdf-b0a1d324f0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "E: List directory /var/lib/apt/lists/partial is missing. - Acquire (13: Permission denied)\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "/bin/bash: line 1: yum: command not found\n"
     ]
    }
   ],
   "source": [
    "!apt-get update\n",
    "!apt-get install zip -y\n",
    "!yum install zip -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b25ee610-3cc5-4ba5-af8e-055ab0b79e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Created cropped_output.zip\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# 폴더 \"cropped_output\"을 \"cropped_output.zip\"으로 압축\n",
    "shutil.make_archive(\"cropped_output\", \"zip\", \"cropped_output\")\n",
    "\n",
    "print(\"Done! Created cropped_output.zip\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:my_env]",
   "language": "python",
   "name": "conda-env-my_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
